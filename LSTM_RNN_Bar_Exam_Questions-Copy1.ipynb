{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow_hub as hub\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained Word2Vec\n",
    "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-500/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to return the maximum length of elems in the dataframe.\n",
    "#This is used to create a fixed length input for the first RNN cell.\n",
    "def get_max_length(df):\n",
    "    max_length = 0\n",
    "    for row in df['feature']:\n",
    "        if len(row.split(\" \")) > max_length:\n",
    "            max_length = len(row.split(\" \"))\n",
    "    return max_length\n",
    "\n",
    "#Return word2vec value for each word in sentence.\n",
    "#add encoded words to numpy array for the first RNN cell.\n",
    "def get_word2vec_enc(features):\n",
    "    encoded_features = []\n",
    "    for feature in features:\n",
    "        tokens = feature.split(\" \")\n",
    "        word2vec_embedding = embed(tokens)\n",
    "        encoded_features.append(word2vec_embedding)\n",
    "    return encoded_features\n",
    "\n",
    "\n",
    "#adding zero padding to all elems such that, they are all the same length\n",
    "def get_padded_encoded_features(encoded_features):\n",
    "    #Longest feature (longest question is hardcoded (from get_max_length()))\n",
    "    max_length = 684\n",
    "    padded_features_encoding = []\n",
    "    for enc_feature in encoded_features:\n",
    "        zero_padding_cnt = max_length - enc_feature.shape[0]\n",
    "        pad = np.zeros((1, 500))\n",
    "        for i in range(zero_padding_cnt):\n",
    "            enc_feature = np.concatenate((pad, enc_feature), axis=0)\n",
    "        padded_features_encoding.append(enc_feature)\n",
    "    return padded_features_encoding\n",
    "\n",
    "#return one hot encoding for isCorrect (Y value for RNN).\n",
    "def answer_encode(answer):\n",
    "    if answer:\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]\n",
    "    \n",
    "\n",
    "#encode strings to numeric value\n",
    "def preprocess(df):\n",
    "    # encode words into word2vec\n",
    "    features = df['feature'].tolist()\n",
    "    \n",
    "    encoded_features = get_word2vec_enc(features)\n",
    "    padded_encoded_features = get_padded_encoded_features(encoded_features)\n",
    "    # encoded answers\n",
    "    answers = df['correct'].tolist()\n",
    "    encoded_answer = [answer_encode(answer) for answer in answers]\n",
    "    X = np.array(padded_encoded_features)\n",
    "    Y = np.array(encoded_answer)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data: \n",
      "4696\n",
      "{'feature': ' The following events took place in a state that  does not recognize common law marriage. The  state does recognize the common law estate of  tenancy by the entirety and has no statute on the  subject. Wade Sloan and Mary Isaacs, who were never  formally married, lived together over a sevenyear period. During this time Mary identified  herself as “Mrs. Sloan” with the knowledge and  consent of Wade. Wade and Mary maintained  several charge accounts at retail stores under  the names “Mr. and Mrs. Wade Sloan,” and  they filed joint income tax returns as Mr. and  Mrs. Sloan. Within this period Wade decided  to buy a home. The deed was in proper form  and identified the grantees as “Wade Sloan and  Mary Sloan his wife, and their heirs and assigns  forever as tenants by the entirety.” Wade made  a down payment of $10,000 and gave a note and  mortgage for the unpaid balance. Both Wade  and Mary signed the note and mortgage for the  unpaid balance. Both Wade and Mary signed the  note and mortgage as husband and wife. Wade  made the monthly payments as they became due  until he and Mary had a disagreement and he  abandoned her and the house. Mary then made  the payments for three months. She then brought  an action against Wade for partition of the land  in question. The prayer for partition should be (A) denied, because a tenant by the entirety has  no right to partition.', 'correct': False}\n"
     ]
    }
   ],
   "source": [
    "#Read in features from JSON file\n",
    "with open('all_plus_500.json', 'r', encoding=\"utf-8\") as myFileAll:\n",
    "     dataAll = myFileAll.read()\n",
    "\n",
    "#Load all into objects\n",
    "objAll = json.loads(dataAll)\n",
    "print(\"Size of data: \")\n",
    "print(len(objAll))\n",
    "\n",
    "##Shuffle our data so our model \"doesn't learn patterns\"\n",
    "random.shuffle(objAll)\n",
    "\n",
    "#Split data into train/test (80/20) \n",
    "print(objAll[1])\n",
    "train_data = objAll[:3757]\n",
    "test_data = objAll[3757:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "3757\n",
      "939\n"
     ]
    }
   ],
   "source": [
    "print(type(objAll))\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.57 GiB for an array with shape (3757, 684, 500) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-781132fe88bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Preprocessing for Train/Test data frames for model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-96f11ff48230>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0manswers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'correct'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mencoded_answer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0manswer_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_encoded_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_answer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.57 GiB for an array with shape (3757, 684, 500) and data type float64"
     ]
    }
   ],
   "source": [
    "#Preprocessing for Train/Test data frames for model\n",
    "df = pd.DataFrame(train_data)\n",
    "train_X, train_Y = preprocess(df)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_X, test_Y = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model two layers of Bi-LSTMs\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64,  return_sequences=True)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on data\n",
    "history = model.fit(train_X, train_Y,epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on test_data\n",
    "random.shuffle(test_X)\n",
    "random.shuffle(test_Y)\n",
    "score, acc = model.evaluate(test_X, test_Y, verbose=1)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy Curves - RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(128,  return_sequences=True))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(LSTM(32))\n",
    "model1.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(train_X, train_Y,epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(128,  return_sequences=True))\n",
    "model2.add(Dropout(0.15))\n",
    "model2.add(LSTM(32))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(train_X, train_Y,epochs=5, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
